{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7abc878-b8c4-4887-868e-3de74c198cb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import os.path as osp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from skimage.morphology import skeletonize\n",
    "from skimage.morphology import thin\n",
    "from skimage import data\n",
    "from skimage.util import invert\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import hog\n",
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler #, cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7549dbb-2acd-4985-a638-a1211b0cc062",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract Desciptors for the list of images\n",
    "def extract_sift_features(list_image):\n",
    "\n",
    "    image_descriptors = []\n",
    "    sift = cv2.SIFT_create()\n",
    "    for image in list_image:\n",
    "        _, descriptor = sift.detectAndCompute(image, None)\n",
    "        \n",
    "       \n",
    "        image_descriptors.append(descriptor)\n",
    "\n",
    "    return image_descriptors\n",
    "\n",
    "#Create k-means bow\n",
    "# We basically take descriptors for all images (all_descriptors= list of descriptor for each image)\n",
    "#  and then we run k-means clustering to put them in groups\n",
    "# then we return the cluster centers as bag of words dictionary\n",
    "\n",
    "def kmean_bow(all_descriptors, num_cluster):\n",
    "    bow_dict = []\n",
    "\n",
    "    kmeans = KMeans(n_clusters = num_cluster)\n",
    "    kmeans.fit(all_descriptors)\n",
    "\n",
    "    bow_dict = kmeans.cluster_centers_\n",
    "\n",
    "    #if not os.path.isfile('bow_dictionary.pkl'):\n",
    "    #    pickle.dump(bow_dict, open('bow_dictionary.pkl', 'wb'))\n",
    "\n",
    "    return bow_dict\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8118ddc0-a242-44cf-a8e4-55ab8dba5cc1",
   "metadata": {},
   "source": [
    "### Now let us build a feature vector\n",
    "\n",
    "##### a) Each image has x number of descriptors (let us call these descriptor-set)\n",
    "#####  b) for each descriptor-set, find the spatial distance to each cluster's center\n",
    "##### c) For every descriptor in the descriptor-set , Find the cluster it is nearest to\n",
    "##### d) Now we have a vector of cluster numbers to which the image is closest to\n",
    "##### e) So finally, build number of features of size = num_cluster, where value of each feature represents a cluster and how many descriptors of the image belong to that cluster\n",
    "##### f) So this feature vector wil have values ranging from 0 to number of descriptors for the image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "959ed616-1656-4746-a8ee-2f98c1e0bced",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create feature vecor \n",
    "# this vector is the assignment to the  of the descriptor from each cluster\n",
    "def create_feature_bow(image_descriptors, BoW, num_cluster):\n",
    "\n",
    "    X_features = []\n",
    "\n",
    "    for i in range(len(image_descriptors)):\n",
    "        features = np.array([0] * num_cluster)\n",
    "\n",
    "        if image_descriptors[i] is not None:\n",
    "            distance = cdist(image_descriptors[i], BoW)\n",
    "\n",
    "            argmin = np.argmin(distance, axis = 1)\n",
    "\n",
    "            for j in argmin:\n",
    "                features[j] += 1\n",
    "        X_features.append(features)\n",
    "\n",
    "    return X_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7188b55e-bcf9-4472-a617-001e5f9b11cc",
   "metadata": {},
   "source": [
    "## Extract SIFT feature from the image dataframe of yg_ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9e0e393-a752-45eb-9b10-01d28e54912d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_path = '/home/ubuntu/data/yg_ar/image_hard_df.pkl'\n",
    "siftdesc_df = '/home/ubuntu/data/yg_ar/image_hard_df_sift_amiya.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c80ed55-0c83-4063-b0b5-5ad4b73e3791",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now extracting descriptors BOW..\n",
      "Now building descriptors BOW..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now creating the features..\n",
      "Now saving the dataframe...\n",
      "All Done.\n"
     ]
    }
   ],
   "source": [
    "NUM_CLUSTERS = 60 \n",
    "\n",
    "###########################################################\n",
    "# get images (builds a list of images\n",
    "#\n",
    "###########################################################\n",
    "df = pd.read_pickle(df_path)\n",
    "images = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    #if index > 2000:\n",
    "    #    break\n",
    "    #print(row)\n",
    "    img = np.array(row[\"image\"])\n",
    "    images.append(img)\n",
    "\n",
    "###########################################################\n",
    "# Extract SIFT descriptors\n",
    "#\n",
    "###########################################################\n",
    "print(\"Now extracting descriptors BOW..\")\n",
    "image_desctiptors = extract_sift_features(np.array(images))\n",
    "\n",
    "###########################################################\n",
    "# Now we will use k-means for building bag of words\n",
    "#\n",
    "###########################################################\n",
    "print(\"Now building descriptors BOW..\")\n",
    "# For this, we need to use the entire vocabulary (all the descriptors of all the images)\n",
    "all_descriptors = []\n",
    "for descriptor in image_desctiptors:\n",
    "    if descriptor is not None:\n",
    "        for des in descriptor:\n",
    "            all_descriptors.append(des)\n",
    "\n",
    "\n",
    "# We will create a cluster of NUM_CLUSTERS for bag of words            \n",
    "BoW = kmean_bow(all_descriptors, NUM_CLUSTERS)\n",
    "\n",
    "###########################################################\n",
    "# Now utilizing the bag of words, we will create feature for each image\n",
    "#\n",
    "###########################################################\n",
    "print(\"Now creating the features..\")\n",
    "X_features = create_feature_bow(image_desctiptors, BoW, NUM_CLUSTERS)\n",
    "\n",
    "#Then we will save it to the df.\n",
    "print(\"Now saving the dataframe...\")\n",
    "df[\"image\"] = X_features\n",
    "df.to_pickle(siftdesc_df)\n",
    "print(\"All Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2125f8bc-2113-4c32-8292-1ae344a0399a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "114d40a0-dad3-476f-9d4f-9174ce03e437",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/yg_ar/image_hard_df_sift_amiya.pkl\n"
     ]
    }
   ],
   "source": [
    "print(siftdesc_df)\n",
    "df = pd.read_pickle(siftdesc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0c16ca5-b9b3-4300-9e75-83c875a18f7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label_a</th>\n",
       "      <th>label_at</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 1, 4, 1, 2, 1, 1, 0, 0, 3, 2, 0, 0, 2, ...</td>\n",
       "      <td>camel</td>\n",
       "      <td>camel_1</td>\n",
       "      <td>camel_1_hair_0_cloth_0_pants_0_Z1031_XON17_YON...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 0, 1, 1, 0, 3, 2, 0, 0, 0, 2, 2, 3, 1, 2, ...</td>\n",
       "      <td>camel</td>\n",
       "      <td>camel_1</td>\n",
       "      <td>camel_1_hair_0_cloth_0_pants_0_Z1095_XOP17_YON...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 0, 0, 0, 0, 7, 0, 2, 1, 0, 0, 0, 0, 0, 2, ...</td>\n",
       "      <td>camel</td>\n",
       "      <td>camel_1</td>\n",
       "      <td>camel_1_hair_0_cloth_0_pants_0_Z1117_XON28_YOP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 2, ...</td>\n",
       "      <td>camel</td>\n",
       "      <td>camel_1</td>\n",
       "      <td>camel_1_hair_0_cloth_0_pants_0_Z1120_XON1_YOP0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 2, 3, 1, 0, 4, 0, 0, 1, 1, 0, 0, 1, 2, 1, ...</td>\n",
       "      <td>camel</td>\n",
       "      <td>camel_1</td>\n",
       "      <td>camel_1_hair_0_cloth_0_pants_0_Z1144_XOP5_YOP1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image label_a label_at  \\\n",
       "0  [1, 2, 1, 4, 1, 2, 1, 1, 0, 0, 3, 2, 0, 0, 2, ...   camel  camel_1   \n",
       "1  [0, 0, 1, 1, 0, 3, 2, 0, 0, 0, 2, 2, 3, 1, 2, ...   camel  camel_1   \n",
       "2  [0, 0, 0, 0, 0, 7, 0, 2, 1, 0, 0, 0, 0, 0, 2, ...   camel  camel_1   \n",
       "3  [1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 2, ...   camel  camel_1   \n",
       "4  [0, 2, 3, 1, 0, 4, 0, 0, 1, 1, 0, 0, 1, 2, 1, ...   camel  camel_1   \n",
       "\n",
       "                                           file_name  \n",
       "0  camel_1_hair_0_cloth_0_pants_0_Z1031_XON17_YON...  \n",
       "1  camel_1_hair_0_cloth_0_pants_0_Z1095_XOP17_YON...  \n",
       "2  camel_1_hair_0_cloth_0_pants_0_Z1117_XON28_YOP...  \n",
       "3  camel_1_hair_0_cloth_0_pants_0_Z1120_XON1_YOP0...  \n",
       "4  camel_1_hair_0_cloth_0_pants_0_Z1144_XOP5_YOP1...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d30e9b40-3d62-49c1-9243-755c8cba2cd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 4, 1, 2, 1, 1, 0, 0, 3, 2, 0, 0, 2, 2, 1, 1, 0, 1, 0, 2,\n",
       "       1, 2, 6, 2, 2, 0, 1, 0, 1, 0, 3, 0, 1, 0, 0, 1, 2, 1, 1, 1, 1, 2,\n",
       "       0, 2, 0, 1, 0, 1, 0, 3, 1, 2, 3, 0, 4, 3, 0, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"image\"].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e34a8a-e25d-417d-a9bd-4c31812feb07",
   "metadata": {},
   "source": [
    "### test the newly built dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26f18a3c-c5fd-45fd-b3c2-9469786ad81c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = []\n",
    "labels = []\n",
    "# get images and titles\n",
    "for index, row in df.iterrows():\n",
    "    #if index > 2000:\n",
    "    #    break\n",
    "    #print(row)\n",
    "    img = np.array(row[\"image\"])\n",
    "    features.append(img)\n",
    "    labels.append( row[\"label_a\"])\n",
    "\n",
    "data_train = np.array(features)\n",
    "label = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f5ea236e-479d-431f-a16b-183dc4b20345",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(data_train,label, test_size = 0.2, random_state = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "89ef65de-7760-45fe-b227-1ff9788d6573",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "svclassifier = SVC(kernel = \"poly\", degree = 8, C=20)\n",
    "svclassifier.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = svclassifier.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4a11d5b7-6d99-4d39-9ee4-4d549df78721",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[263  10  74  18  15  11   1  11  10   3]\n",
      " [ 24 182  96  24   7  14   4   9  10  35]\n",
      " [ 53  24 267   9   7  39   8   7   1   7]\n",
      " [  6   9   1 317   3   2   7   2  20  13]\n",
      " [ 47  13 149  20 142  23  10   7   4   7]\n",
      " [ 42  12 116  17   6 177   8   7   3  26]\n",
      " [  6  15  82  56  11  13 148   9  25  23]\n",
      " [ 49  13 134   6   4  13   5 143   1  16]\n",
      " [  1   2   1   9   0   3  10   0 380   2]\n",
      " [  3  16  67  23   5   4   2   4   8 229]]\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "            camel       0.53      0.63      0.58       416\n",
      "            chair       0.61      0.45      0.52       405\n",
      "           childs       0.27      0.63      0.38       422\n",
      "lord_of_the_dance       0.64      0.83      0.72       380\n",
      "            lotus       0.71      0.34      0.46       422\n",
      "      thunderbolt       0.59      0.43      0.50       414\n",
      "         triangle       0.73      0.38      0.50       388\n",
      "       upward_dog       0.72      0.37      0.49       384\n",
      "       warrior_II       0.82      0.93      0.87       408\n",
      "      warrior_III       0.63      0.63      0.63       361\n",
      "\n",
      "         accuracy                           0.56      4000\n",
      "        macro avg       0.63      0.56      0.56      4000\n",
      "     weighted avg       0.62      0.56      0.56      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test,Y_pred))\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac68f4fa-04e9-4ef6-a0ff-8371d42cd93c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score:  0.7691874999999999\n",
      "best_params:  {'C': 20}\n"
     ]
    }
   ],
   "source": [
    "model_svm = SVC(C = 30, random_state = 0)\n",
    "parameters = [\n",
    "     {'C': [20, 25, 30, 35, 40, 45]}\n",
    " ]\n",
    "grid_model = GridSearchCV(\n",
    "     estimator = model_svm,\n",
    "     param_grid = parameters,\n",
    "     cv = 10\n",
    " )\n",
    "grid_model.fit(X_train, Y_train)\n",
    "\n",
    "#model_svm.fit(X_train, Y_train)\n",
    "filename = 'svm_model.sav'\n",
    "#pickle.dump(model_svm, open(filename, 'wb'))\n",
    "#print(\"score on training set params: \", model_svm.score(X_train, Y_train))\n",
    "#print(\"score on testing set params: \", model_svm.score(X_test, Y_test))\n",
    "print(\"best score: \", grid_model.best_score_)\n",
    "print(\"best_params: \", grid_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233f9498-8695-4f2b-9fda-7c55e007be14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
