{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41689ce4-5d32-4ee6-9438-e02fea09d601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import os.path as osp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from skimage.morphology import skeletonize\n",
    "from skimage.util import invert\n",
    "from nebula.common import to_scale_one, write_pickle, read_pickle, display, display_color\n",
    "from nebula.data.yg_ar.setup_data_image_hard import split_ar_anim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f7f0b8f-f57d-4fa7-a4cc-339913d6ceb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loc_frame_from_data(data, loc=0.5):\n",
    "    count = data.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    f_loc = int((count-1) * loc)\n",
    "    \n",
    "    data.set(cv2.CAP_PROP_POS_FRAMES, f_loc)\n",
    "    ret, frame = data.read()\n",
    "    \n",
    "    return frame\n",
    "    \n",
    "    \n",
    "def get_loc_frame(path, loc=0.5):\n",
    "    data = cv2.VideoCapture(path)\n",
    "    return get_loc_frame_from_data(data, loc=loc)\n",
    "\n",
    "\n",
    "def get_n_frames(path, n=8):\n",
    "    data = cv2.VideoCapture(path)\n",
    "    res = [get_loc_frame_from_data(data, loc=i/n) for i in range(n)]\n",
    "    \n",
    "    return res\n",
    "\n",
    "\n",
    "def get_locs_frames(path, locs=[0.15, 0.5, 0.85]):\n",
    "    data = cv2.VideoCapture(path)\n",
    "    res = [get_loc_frame_from_data(data, loc=loc) for loc in locs]\n",
    "    return res\n",
    "    \n",
    "\n",
    "def to_gray_one(frame):\n",
    "    return cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "def to_gray(frames):\n",
    "    res = [to_gray_one(f) for f in frames]\n",
    "    return res\n",
    "\n",
    "\n",
    "def crop_one(frame, top, bottom, left, right):\n",
    "    return frame[top:-bottom, left:-right]\n",
    "\n",
    "\n",
    "def crop(frames, top, bottom, left, right):\n",
    "    res = [crop_one(f, top, bottom, left, right) for f in frames]\n",
    "    return res\n",
    "\n",
    "\n",
    "def save_frame(path, frame):\n",
    "    cv2.imwrite(path, frame)\n",
    "    \n",
    "\n",
    "def read_gray_frame(path):\n",
    "    return cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    \n",
    "def to_jpg_name(file):\n",
    "    return file.split(\".\")[0] + \".jpg\"\n",
    "\n",
    "\n",
    "def to_pickle_name(file):\n",
    "    return file.split(\".\")[0] + \".pkl\"\n",
    "\n",
    "\n",
    "def get_files(dir, format=None):\n",
    "    res = []\n",
    "    for filename in os.listdir(dir):\n",
    "        if format is None or filename.split(\".\")[-1] == format:\n",
    "            res.append(filename)\n",
    "    return res\n",
    "\n",
    "\n",
    "def filename_to_labels(filename):\n",
    "    \n",
    "    filename = filename.split(\".\")[0]\n",
    "    words = filename.split(\"_\")\n",
    "    \n",
    "    orientation = words[-1]\n",
    "    xangle = words[-2]\n",
    "    yangle = words[-3]\n",
    "    pants = words[-4]\n",
    "    cloth = words[-6]\n",
    "    hair = words[-8]\n",
    "    action_type = words[-10]\n",
    "    label = \"_\".join(words[:-10])\n",
    "    \n",
    "    return (\n",
    "        orientation, \n",
    "        xangle, \n",
    "        yangle, \n",
    "        pants, \n",
    "        cloth, \n",
    "        hair, \n",
    "        action_type, \n",
    "        label\n",
    "    )\n",
    "\n",
    "\n",
    "def filename_to_labels_hard(filename):\n",
    "    \n",
    "    filename = filename.split(\".\")[0]\n",
    "    words = filename.split(\"_\")\n",
    "    \n",
    "    action = \"_\".join(words[:-12])\n",
    "    action_type = words[-12]\n",
    "    \n",
    "    label_a = action\n",
    "    label_at = \"_\".join([action, action_type])\n",
    "    \n",
    "    return (\n",
    "        label_a,\n",
    "        label_at,\n",
    "        filename\n",
    "    )\n",
    "\n",
    "\n",
    "def read_pickle(dir):\n",
    "    with open(dir, 'rb') as handle:\n",
    "        b = pickle.load(handle)\n",
    "    return b\n",
    "\n",
    "\n",
    "def write_pickle(dir, data):\n",
    "    with open(dir, 'wb') as handle:\n",
    "        pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6308f76-c151-41c2-88bc-b7ba06a40882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_middle_frame(\n",
    "    base_dir,\n",
    "    save_dir,\n",
    "    overwrite=False,\n",
    "    crop=dict(top=70, bottom=30, left=50, right=50)\n",
    "):\n",
    "    if not osp.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    files = get_files(base_dir)\n",
    "    count = len(files)\n",
    "    prev_progress = 0\n",
    "    for i, file in enumerate(files):\n",
    "        save_file = osp.join(save_dir, to_jpg_name(file))\n",
    "        if osp.exists(save_file) and not overwrite:\n",
    "            continue\n",
    "        \n",
    "        path = osp.join(base_dir, file)\n",
    "        frame = to_gray_one(crop_one(get_loc_frame(path), **crop))\n",
    "        \n",
    "        save_frame(save_file, frame)\n",
    "        \n",
    "        cur_progress = int((i+1)*100/count)\n",
    "        if cur_progress >= prev_progress + 2:\n",
    "            print(f\"progress: {cur_progress}%\")\n",
    "            prev_progress = cur_progress\n",
    "            \n",
    "\n",
    "def df_middle_frame(\n",
    "    image_dir,\n",
    "    save_path,\n",
    "):\n",
    "    files = get_files(image_dir)\n",
    "    count = len(files)\n",
    "    print(count)\n",
    "    prev_progress = 0\n",
    "    res = []\n",
    "    for i, f in enumerate(files):\n",
    "        frame = read_gray_frame(osp.join(image_dir, f))\n",
    "        (\n",
    "            label_a,\n",
    "            label_ac,\n",
    "            fname\n",
    "        ) = filename_to_labels_hard(f)\n",
    "        \n",
    "        res.append(\n",
    "            (\n",
    "                frame, \n",
    "                label_a,\n",
    "                label_ac,\n",
    "                fname\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        cur_progress = int((i+1)*100/count)\n",
    "        if cur_progress >= prev_progress + 2:\n",
    "            print(f\"progress: {cur_progress}%\")\n",
    "            prev_progress = cur_progress\n",
    "\n",
    "    df = pd.DataFrame(data=dict(zip(\n",
    "        [\n",
    "            \"image\", \n",
    "            \"label_a\",\n",
    "            \"label_at\",\n",
    "            \"file_name\"\n",
    "        ], \n",
    "        np.transpose(res)\n",
    "    )))\n",
    "    \n",
    "    df.to_pickle(save_path)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "438c6e2a-bbf5-4f12-aff4-fa0aaecb046f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_locs_frames(\n",
    "    base_dir,\n",
    "    save_dir,\n",
    "    overwrite=False,\n",
    "    crop=dict(top=70, bottom=30, left=50, right=50),\n",
    "    locs=[0.15, 0.5, 0.85]\n",
    "):\n",
    "    if not osp.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    files = get_files(base_dir)\n",
    "    count = len(files)\n",
    "    prev_progress = 0\n",
    "    for i, file in enumerate(files):\n",
    "        save_file = osp.join(save_dir, to_pickle_name(file))\n",
    "        if osp.exists(save_file) and not overwrite:\n",
    "            continue\n",
    "        \n",
    "        path = osp.join(base_dir, file)\n",
    "        frames = get_locs_frames(path, locs=locs)\n",
    "        frames = [to_gray_one(crop_one(f, **crop)) for f in frames]\n",
    "        \n",
    "        write_pickle(save_file, frames)\n",
    "        \n",
    "        cur_progress = int((i+1)*100/count)\n",
    "        if cur_progress >= prev_progress + 2:\n",
    "            print(f\"progress: {cur_progress}%\")\n",
    "            prev_progress = cur_progress\n",
    "            \n",
    "\n",
    "def df_locs_frames(\n",
    "    pickle_dir,\n",
    "    save_path,\n",
    "):\n",
    "    files = get_files(pickle_dir)\n",
    "    count = len(files)\n",
    "    print(count)\n",
    "    prev_progress = 0\n",
    "    res = []\n",
    "    for i, f in enumerate(files):\n",
    "        frames = read_pickle(osp.join(pickle_dir, f))\n",
    "        (\n",
    "            label_a,\n",
    "            label_ac,\n",
    "            fname\n",
    "        ) = filename_to_labels_hard(f)\n",
    "        \n",
    "        res.append(\n",
    "            (\n",
    "                frames, \n",
    "                label_a,\n",
    "                label_ac,\n",
    "                fname\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        cur_progress = int((i+1)*100/count)\n",
    "        if cur_progress >= prev_progress + 2:\n",
    "            print(f\"progress: {cur_progress}%\")\n",
    "            prev_progress = cur_progress\n",
    "\n",
    "    df = pd.DataFrame(data=dict(zip(\n",
    "        [\n",
    "            \"images\", \n",
    "            \"label_a\",\n",
    "            \"label_at\",\n",
    "            \"file_name\"\n",
    "        ], \n",
    "        np.transpose(res)\n",
    "    )))\n",
    "    \n",
    "    df.to_pickle(save_path)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95381148-6e11-4da7-96e4-6c0478790aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "from scipy import ndimage\n",
    "import random\n",
    "\n",
    "\n",
    "def zoom(frame, x, y, z=100):\n",
    "    img = Image.fromarray(frame)\n",
    "    w, h = img.size\n",
    "    z2 = z * 2/100.0\n",
    "    img = img.crop((x - w / z2, y - h / z2, \n",
    "                    x + w / z2, y + h / z2))\n",
    "    img = img.resize((w, h), Image.LANCZOS)\n",
    "    return np.asarray(img)\n",
    "\n",
    "\n",
    "def rotate(frame, degree):\n",
    "    return ndimage.rotate(frame, degree, reshape=False)\n",
    "\n",
    "\n",
    "def random_zoom(frame, min_loc=-10, max_loc=10, min_z=100, max_z=130):\n",
    "    \n",
    "    h, w = frame.shape\n",
    "    \n",
    "    x_offset = random.randint(min_loc, max_loc)\n",
    "    y_offset = random.randint(min_loc, max_loc)\n",
    "    z = random.randint(min_z, max_z)\n",
    "    \n",
    "    return zoom(frame, int(w/2)+x_offset, int(h/2)+y_offset, z)\n",
    "\n",
    "\n",
    "def random_rotate(frame, min_d=-10, max_d=10):\n",
    "    \n",
    "    deg = random.randint(min_d, max_d)\n",
    "    return rotate(frame, deg)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94e0b044-b609-4a7f-b7ca-362b02ecc2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'C:/Users/aphri/Documents/t0002/pycharm/data/yg_ar/videos_hard'\n",
    "save_dir = 'C:/Users/aphri/Documents/t0002/pycharm/data/yg_ar/v5f_hard'\n",
    "v5f_pickle_path = 'C:/Users/aphri/Documents/t0002/pycharm/data/yg_ar/v5f_hard_df.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "890367cd-a164-4ac1-b1a3-0323f4e38e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress: 2%\n",
      "progress: 4%\n",
      "progress: 6%\n",
      "progress: 8%\n",
      "progress: 10%\n",
      "progress: 12%\n",
      "progress: 14%\n",
      "progress: 16%\n",
      "progress: 18%\n",
      "progress: 20%\n",
      "progress: 22%\n",
      "progress: 24%\n",
      "progress: 26%\n",
      "progress: 28%\n",
      "progress: 30%\n",
      "progress: 32%\n",
      "progress: 34%\n",
      "progress: 36%\n",
      "progress: 38%\n",
      "progress: 40%\n",
      "progress: 42%\n",
      "progress: 44%\n",
      "progress: 46%\n",
      "progress: 48%\n",
      "progress: 50%\n",
      "progress: 52%\n",
      "progress: 54%\n",
      "progress: 56%\n",
      "progress: 58%\n",
      "progress: 60%\n",
      "progress: 62%\n",
      "progress: 64%\n",
      "progress: 66%\n",
      "progress: 68%\n",
      "progress: 70%\n",
      "progress: 72%\n",
      "progress: 74%\n",
      "progress: 76%\n",
      "progress: 78%\n",
      "progress: 80%\n",
      "progress: 82%\n",
      "progress: 84%\n",
      "progress: 86%\n",
      "progress: 88%\n",
      "progress: 90%\n",
      "progress: 92%\n",
      "progress: 94%\n",
      "progress: 96%\n",
      "progress: 98%\n",
      "progress: 100%\n"
     ]
    }
   ],
   "source": [
    "convert_locs_frames(\n",
    "    base_dir=base_dir,\n",
    "    save_dir=save_dir,\n",
    "    overwrite=False,\n",
    "    crop=dict(top=70, bottom=30, left=50, right=50),\n",
    "    locs=[0.1, 0.3, 0.5, 0.7, 0.9]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2dc4fd4-07f5-4ecc-8290-f015b5991a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "progress: 2%\n",
      "progress: 4%\n",
      "progress: 6%\n",
      "progress: 8%\n",
      "progress: 10%\n",
      "progress: 12%\n",
      "progress: 14%\n",
      "progress: 16%\n",
      "progress: 18%\n",
      "progress: 20%\n",
      "progress: 22%\n",
      "progress: 24%\n",
      "progress: 26%\n",
      "progress: 28%\n",
      "progress: 30%\n",
      "progress: 32%\n",
      "progress: 34%\n",
      "progress: 36%\n",
      "progress: 38%\n",
      "progress: 40%\n",
      "progress: 42%\n",
      "progress: 44%\n",
      "progress: 46%\n",
      "progress: 48%\n",
      "progress: 50%\n",
      "progress: 52%\n",
      "progress: 54%\n",
      "progress: 56%\n",
      "progress: 58%\n",
      "progress: 60%\n",
      "progress: 62%\n",
      "progress: 64%\n",
      "progress: 66%\n",
      "progress: 68%\n",
      "progress: 70%\n",
      "progress: 72%\n",
      "progress: 74%\n",
      "progress: 76%\n",
      "progress: 78%\n",
      "progress: 80%\n",
      "progress: 82%\n",
      "progress: 84%\n",
      "progress: 86%\n",
      "progress: 88%\n",
      "progress: 90%\n",
      "progress: 92%\n",
      "progress: 94%\n",
      "progress: 96%\n",
      "progress: 98%\n",
      "progress: 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aphri\\miniconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = getattr(asarray(obj), method)(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>label_a</th>\n",
       "      <th>label_at</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26,...</td>\n",
       "      <td>camel</td>\n",
       "      <td>camel_1</td>\n",
       "      <td>camel_1_hair_0_cloth_0_pants_0_Z1031_XON17_YON...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[12, 12, 12, 11, 11, 12, 12, 12, 12, 12, 12,...</td>\n",
       "      <td>camel</td>\n",
       "      <td>camel_1</td>\n",
       "      <td>camel_1_hair_0_cloth_0_pants_0_Z1095_XOP17_YON...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[44, 44, 44, 44, 44, 44, 43, 43, 45, 45, 45,...</td>\n",
       "      <td>camel</td>\n",
       "      <td>camel_1</td>\n",
       "      <td>camel_1_hair_0_cloth_0_pants_0_Z1117_XON28_YOP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[85, 87, 92, 93, 84, 90, 89, 87, 87, 87, 90,...</td>\n",
       "      <td>camel</td>\n",
       "      <td>camel_1</td>\n",
       "      <td>camel_1_hair_0_cloth_0_pants_0_Z1120_XON1_YOP0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,...</td>\n",
       "      <td>camel</td>\n",
       "      <td>camel_1</td>\n",
       "      <td>camel_1_hair_0_cloth_0_pants_0_Z1144_XOP5_YOP1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>[[[90, 89, 88, 89, 88, 89, 88, 87, 90, 97, 89,...</td>\n",
       "      <td>warrior_II</td>\n",
       "      <td>warrior_II_4</td>\n",
       "      <td>warrior_II_4_hair_3_cloth_3_pants_0_Z940_XOP30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>[[[18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,...</td>\n",
       "      <td>warrior_II</td>\n",
       "      <td>warrior_II_4</td>\n",
       "      <td>warrior_II_4_hair_3_cloth_3_pants_0_Z958_XON23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>[[[23, 23, 23, 23, 22, 22, 22, 22, 23, 22, 22,...</td>\n",
       "      <td>warrior_II</td>\n",
       "      <td>warrior_II_4</td>\n",
       "      <td>warrior_II_4_hair_3_cloth_3_pants_0_Z972_XOP6_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>[[[19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,...</td>\n",
       "      <td>warrior_II</td>\n",
       "      <td>warrior_II_4</td>\n",
       "      <td>warrior_II_4_hair_3_cloth_3_pants_0_Z987_XOP19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>[[[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 49,...</td>\n",
       "      <td>warrior_II</td>\n",
       "      <td>warrior_II_4</td>\n",
       "      <td>warrior_II_4_hair_3_cloth_3_pants_0_Z998_XON20...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  images     label_a  \\\n",
       "0      [[[26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26,...       camel   \n",
       "1      [[[12, 12, 12, 11, 11, 12, 12, 12, 12, 12, 12,...       camel   \n",
       "2      [[[44, 44, 44, 44, 44, 44, 43, 43, 45, 45, 45,...       camel   \n",
       "3      [[[85, 87, 92, 93, 84, 90, 89, 87, 87, 87, 90,...       camel   \n",
       "4      [[[18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,...       camel   \n",
       "...                                                  ...         ...   \n",
       "19995  [[[90, 89, 88, 89, 88, 89, 88, 87, 90, 97, 89,...  warrior_II   \n",
       "19996  [[[18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,...  warrior_II   \n",
       "19997  [[[23, 23, 23, 23, 22, 22, 22, 22, 23, 22, 22,...  warrior_II   \n",
       "19998  [[[19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,...  warrior_II   \n",
       "19999  [[[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 49,...  warrior_II   \n",
       "\n",
       "           label_at                                          file_name  \n",
       "0           camel_1  camel_1_hair_0_cloth_0_pants_0_Z1031_XON17_YON...  \n",
       "1           camel_1  camel_1_hair_0_cloth_0_pants_0_Z1095_XOP17_YON...  \n",
       "2           camel_1  camel_1_hair_0_cloth_0_pants_0_Z1117_XON28_YOP...  \n",
       "3           camel_1  camel_1_hair_0_cloth_0_pants_0_Z1120_XON1_YOP0...  \n",
       "4           camel_1  camel_1_hair_0_cloth_0_pants_0_Z1144_XOP5_YOP1...  \n",
       "...             ...                                                ...  \n",
       "19995  warrior_II_4  warrior_II_4_hair_3_cloth_3_pants_0_Z940_XOP30...  \n",
       "19996  warrior_II_4  warrior_II_4_hair_3_cloth_3_pants_0_Z958_XON23...  \n",
       "19997  warrior_II_4  warrior_II_4_hair_3_cloth_3_pants_0_Z972_XOP6_...  \n",
       "19998  warrior_II_4  warrior_II_4_hair_3_cloth_3_pants_0_Z987_XOP19...  \n",
       "19999  warrior_II_4  warrior_II_4_hair_3_cloth_3_pants_0_Z998_XON20...  \n",
       "\n",
       "[20000 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_locs_frames(\n",
    "    pickle_dir=save_dir,\n",
    "    save_path=v5f_pickle_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea806422-35e9-42e4-9916-7fcb233aa6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_pickle(v5f_pickle_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56262ff3-9e67-461b-a6e5-ea40a802bcec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156, 156)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"images\"].iloc[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2074201-c8af-49c2-97ab-d49d914f9ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"images\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f5924e-9794-4910-8593-7a627ae091ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (156, 156, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
