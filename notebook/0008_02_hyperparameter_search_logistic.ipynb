{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b21268a-5c59-4575-a591-afcd0fa11b51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nebula.data.yg_ar.setup_data_image_hard import read_data\n",
    "from nebula.common import to_scale_one, write_pickle, read_pickle\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46971ecd-13ed-4b89-b842-3c145c3596c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model, test_x, test_y):\n",
    "    res = model.predict(test_x)\n",
    "    correct = res == test_y\n",
    "    accuracy = correct.sum() / len(res)\n",
    "    return res, accuracy\n",
    "\n",
    "\n",
    "def create_dirs_to_file(path):\n",
    "    dirs = \"/\".join(osp.join(path).split(\"/\")[:-1])\n",
    "    if not osp.exists(dirs):\n",
    "        os.makedirs(dirs)\n",
    "\n",
    "\n",
    "def load_or_train(train_x, train_y, test_x, test_y, train_func, label_map, path):\n",
    "    \n",
    "    if osp.exists(path):\n",
    "        return read_pickle(path)\n",
    "    \n",
    "    create_dirs_to_file(path)\n",
    "    \n",
    "    trained_model = train_func(train_x, train_y)\n",
    "    predictions, accuracy = evaluate(trained_model, test_x, test_y)\n",
    "    \n",
    "    df, df_incorrect, df_correct = format_results(predictions, test_y, label_map)\n",
    "    \n",
    "    write_pickle(path, (trained_model, predictions, accuracy, df, df_incorrect, df_correct, label_map)) \n",
    "    \n",
    "    return trained_model, predictions, accuracy, df, df_incorrect, df_correct, label_map\n",
    "\n",
    "\n",
    "def format_results(predictions, labels, label_map):\n",
    "    df = pd.DataFrame(\n",
    "        data={\n",
    "            \"prediction\": predictions,\n",
    "            \"label\": labels\n",
    "        }\n",
    "    )\n",
    "    df[\"check\"] = df[\"prediction\"] == df[\"label\"]\n",
    "\n",
    "    label_map_reverse = {v:k for k, v in label_map.items()}\n",
    "\n",
    "    df[\"prediction_name\"] = df.prediction.map(label_map_reverse)\n",
    "    df[\"label_name\"] = df.label.map(label_map_reverse)\n",
    "\n",
    "    df_incorrect = df[~df.check]\n",
    "    df_correct = df[df.check]\n",
    "\n",
    "    return df, df_incorrect, df_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d6aa2df-d80c-403c-b0a9-33557679ae7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_label_map(labels):\n",
    "    label_set = set()\n",
    "    for lt in labels:\n",
    "        label_set.add(lt)\n",
    "        \n",
    "    label_set = list(label_set)\n",
    "    label_set.sort()\n",
    "\n",
    "    label_map = {}\n",
    "    count = 0\n",
    "    for l in label_set:\n",
    "        label_map[l] = count\n",
    "        count += 1\n",
    "        \n",
    "    return label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ee2c279-2933-4770-ad74-b764d21926e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create data sets\n",
    "df_path_easy = '/home/ubuntu/data/yg_ar/image_easy2_ds_sift_amiya.pkl'\n",
    "df_easy, train_df_easy, test_df_easy, valid_df_easy = read_pickle(df_path_easy)\n",
    "\n",
    "df_path_medium = '/home/ubuntu/data/yg_ar/image_medium_ds_sift_amiya.pkl'\n",
    "df_medium, train_df_medium, test_df_medium, valid_df_medium = read_pickle(df_path_medium)\n",
    "                                                                  \n",
    "df_path_hard = '/home/ubuntu/data/yg_ar/image_hard_ds_sift_amiya.pkl'\n",
    "df_hard, train_df_hard, test_df_hard, valid_df_hard = read_pickle(df_path_hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9eb9698f-b401-4610-96cc-1aedfd1bd13d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create labels\n",
    "label_map_a_easy = create_label_map(df_easy[\"label_a\"])\n",
    "label_map_at_easy = create_label_map(df_easy[\"label_at\"])\n",
    "\n",
    "label_map_a_medium = create_label_map(df_medium[\"label_a\"])\n",
    "label_map_at_medium = create_label_map(df_medium[\"label_at\"])\n",
    "\n",
    "label_map_a_hard = create_label_map(df_hard[\"label_a\"])\n",
    "label_map_at_hard = create_label_map(df_hard[\"label_at\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bce63941-c9fc-4c11-9fbf-4947ee998238",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_x_easy = train_df_easy[\"image\"].to_list()\n",
    "train_x_medium = train_df_medium[\"image\"].to_list()\n",
    "train_x_hard = train_df_hard[\"image\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fd5319f-95ee-4a1a-a056-c755af2930bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_y_a_easy = train_df_easy[\"label_a\"].map(label_map_a_easy).to_list()\n",
    "train_y_at_easy = train_df_easy[\"label_at\"].map(label_map_at_easy).to_list()\n",
    "\n",
    "train_y_a_medium = train_df_medium[\"label_a\"].map(label_map_a_medium).to_list()\n",
    "train_y_at_medium = train_df_medium[\"label_at\"].map(label_map_at_medium).to_list()\n",
    "\n",
    "train_y_a_hard = train_df_hard[\"label_a\"].map(label_map_a_medium).to_list()\n",
    "train_y_at_hard = train_df_hard[\"label_at\"].map(label_map_at_medium).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f21f1acf-b2c2-4f1d-87f8-093f2da21874",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_x_easy = test_df_easy[\"image\"].to_list()\n",
    "test_x_medium = test_df_medium[\"image\"].to_list()\n",
    "test_x_hard = test_df_hard[\"image\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fefefe69-772d-4d2a-ae8f-88c4f158a291",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_y_a_easy = test_df_easy[\"label_a\"].map(label_map_a_easy).to_list()\n",
    "test_y_at_easy = test_df_easy[\"label_at\"].map(label_map_at_easy).to_list()\n",
    "\n",
    "test_y_a_medium = test_df_medium[\"label_a\"].map(label_map_a_medium).to_list()\n",
    "test_y_at_medium = test_df_medium[\"label_at\"].map(label_map_at_medium).to_list()\n",
    "\n",
    "test_y_a_hard = test_df_hard[\"label_a\"].map(label_map_a_hard).to_list()\n",
    "test_y_at_hard = test_df_hard[\"label_at\"].map(label_map_at_hard).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22884327-365a-47eb-a4f6-c9fcb2d102a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_x_easy = valid_df_easy[\"image\"].to_list()\n",
    "valid_x_medium = valid_df_medium[\"image\"].to_list()\n",
    "valid_x_hard = valid_df_hard[\"image\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "281b0a58-2d23-4193-9f64-a77dcf97e1ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_y_a_easy = valid_df_easy[\"label_a\"].map(label_map_a_easy).to_list()\n",
    "valid_y_at_easy = valid_df_easy[\"label_at\"].map(label_map_at_easy).to_list()\n",
    "\n",
    "valid_y_a_medium = valid_df_medium[\"label_a\"].map(label_map_a_medium).to_list()\n",
    "valid_y_at_medium = valid_df_medium[\"label_at\"].map(label_map_at_medium).to_list()\n",
    "\n",
    "valid_y_a_hard = valid_df_hard[\"label_a\"].map(label_map_a_hard).to_list()\n",
    "valid_y_at_hard = valid_df_hard[\"label_at\"].map(label_map_at_hard).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcfd2701-8d72-4be1-87cf-4dbe9b40d0ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 45 candidates, totalling 90 fits\n",
      "[CV 1/2] END .C=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/2] END .C=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/2] END .....C=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/2] END .....C=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END C=100, penalty=l1, solver=liblinear;, score=0.062 total time=   7.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END C=100, penalty=l1, solver=liblinear;, score=0.070 total time=   5.6s\n",
      "[CV 1/2] END C=100, penalty=l2, solver=newton-cg;, score=0.069 total time=   7.5s\n",
      "[CV 2/2] END C=100, penalty=l2, solver=newton-cg;, score=0.065 total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END ...C=100, penalty=l2, solver=lbfgs;, score=0.074 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END ...C=100, penalty=l2, solver=lbfgs;, score=0.070 total time=   0.4s\n",
      "[CV 1/2] END C=100, penalty=l2, solver=liblinear;, score=0.061 total time=   0.5s\n",
      "[CV 2/2] END C=100, penalty=l2, solver=liblinear;, score=0.069 total time=   0.5s\n",
      "[CV 1/2] END C=100, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/2] END C=100, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/2] END C=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/2] END C=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/2] END C=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/2] END C=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/2] END ..C=10, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/2] END ..C=10, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/2] END ......C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/2] END ......C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/2] END C=10, penalty=l1, solver=liblinear;, score=0.065 total time=   1.4s\n",
      "[CV 2/2] END C=10, penalty=l1, solver=liblinear;, score=0.076 total time=   1.3s\n",
      "[CV 1/2] END C=10, penalty=l2, solver=newton-cg;, score=0.078 total time=   3.0s\n",
      "[CV 2/2] END C=10, penalty=l2, solver=newton-cg;, score=0.074 total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END ....C=10, penalty=l2, solver=lbfgs;, score=0.080 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END ....C=10, penalty=l2, solver=lbfgs;, score=0.072 total time=   0.5s\n",
      "[CV 1/2] END C=10, penalty=l2, solver=liblinear;, score=0.070 total time=   0.4s\n",
      "[CV 2/2] END C=10, penalty=l2, solver=liblinear;, score=0.075 total time=   0.4s\n",
      "[CV 1/2] END C=10, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/2] END C=10, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/2] END C=10, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/2] END C=10, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/2] END C=10, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/2] END C=10, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/2] END .C=1.0, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/2] END .C=1.0, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/2] END .....C=1.0, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/2] END .....C=1.0, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/2] END C=1.0, penalty=l1, solver=liblinear;, score=0.078 total time=   0.5s\n",
      "[CV 2/2] END C=1.0, penalty=l1, solver=liblinear;, score=0.068 total time=   0.5s\n",
      "[CV 1/2] END C=1.0, penalty=l2, solver=newton-cg;, score=0.081 total time=   1.3s\n",
      "[CV 2/2] END C=1.0, penalty=l2, solver=newton-cg;, score=0.081 total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END ...C=1.0, penalty=l2, solver=lbfgs;, score=0.080 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END ...C=1.0, penalty=l2, solver=lbfgs;, score=0.083 total time=   0.6s\n",
      "[CV 1/2] END C=1.0, penalty=l2, solver=liblinear;, score=0.080 total time=   0.3s\n",
      "[CV 2/2] END C=1.0, penalty=l2, solver=liblinear;, score=0.078 total time=   0.3s\n",
      "[CV 1/2] END C=1.0, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/2] END C=1.0, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/2] END C=1.0, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/2] END C=1.0, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/2] END C=1.0, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/2] END C=1.0, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/2] END .C=0.1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/2] END .C=0.1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/2] END .....C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/2] END .....C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/2] END C=0.1, penalty=l1, solver=liblinear;, score=0.060 total time=   0.2s\n",
      "[CV 2/2] END C=0.1, penalty=l1, solver=liblinear;, score=0.061 total time=   0.2s\n",
      "[CV 1/2] END C=0.1, penalty=l2, solver=newton-cg;, score=0.086 total time=   1.2s\n",
      "[CV 2/2] END C=0.1, penalty=l2, solver=newton-cg;, score=0.085 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.086 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.085 total time=   0.5s\n",
      "[CV 1/2] END C=0.1, penalty=l2, solver=liblinear;, score=0.084 total time=   0.2s\n",
      "[CV 2/2] END C=0.1, penalty=l2, solver=liblinear;, score=0.080 total time=   0.2s\n",
      "[CV 1/2] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/2] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/2] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/2] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/2] END C=0.1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/2] END C=0.1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/2] END C=0.01, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/2] END C=0.01, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/2] END ....C=0.01, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/2] END ....C=0.01, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/2] END C=0.01, penalty=l1, solver=liblinear;, score=0.044 total time=   0.1s\n",
      "[CV 2/2] END C=0.01, penalty=l1, solver=liblinear;, score=0.045 total time=   0.1s\n",
      "[CV 1/2] END C=0.01, penalty=l2, solver=newton-cg;, score=0.084 total time=   0.8s\n",
      "[CV 2/2] END C=0.01, penalty=l2, solver=newton-cg;, score=0.082 total time=   0.7s\n",
      "[CV 1/2] END ..C=0.01, penalty=l2, solver=lbfgs;, score=0.084 total time=   0.6s\n",
      "[CV 2/2] END ..C=0.01, penalty=l2, solver=lbfgs;, score=0.082 total time=   0.3s\n",
      "[CV 1/2] END C=0.01, penalty=l2, solver=liblinear;, score=0.094 total time=   0.1s\n",
      "[CV 2/2] END C=0.01, penalty=l2, solver=liblinear;, score=0.076 total time=   0.2s\n",
      "[CV 1/2] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/2] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/2] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/2] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/2] END C=0.01, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/2] END C=0.01, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "50 fits failed out of a total of 90.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ubuntu/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/ubuntu/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ubuntu/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/ubuntu/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ubuntu/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/ubuntu/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ubuntu/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/ubuntu/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/ubuntu/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/ubuntu/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/ubuntu/.local/lib/python3.9/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.06647727 0.06704545 0.07215909 0.06534091\n",
      "        nan        nan        nan        nan        nan 0.07045455\n",
      " 0.07613636 0.07556818 0.07272727        nan        nan        nan\n",
      "        nan        nan 0.07329545 0.08068182 0.08125    0.07897727\n",
      "        nan        nan        nan        nan        nan 0.06079545\n",
      " 0.08579545 0.08579545 0.08181818        nan        nan        nan\n",
      "        nan        nan 0.04488636 0.08295455 0.08295455 0.08522727\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score:  0.08579545454545454\n",
      "best_params:  {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = dict(\n",
    "    solver=['newton-cg', 'lbfgs', 'liblinear'],\n",
    "    penalty=['l1', 'l2', 'elasticnet'],\n",
    "    C=[100, 10, 1.0, 0.1, 0.01]\n",
    ")\n",
    "\n",
    "\n",
    "grid_model = GridSearchCV(\n",
    "    estimator=LogisticRegression(),\n",
    "    param_grid=param_grid,\n",
    "    refit=True,\n",
    "    verbose=3,\n",
    "    cv=2,\n",
    ")\n",
    "\n",
    "grid_model.fit(valid_x_hard, valid_y_at_hard)\n",
    "\n",
    "print(\"best score: \", grid_model.best_score_)\n",
    "print(\"best_params: \", grid_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc7746dd-b172-4da8-9bda-908ebe7c08eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "[CV 1/4] END C=0.3, penalty=l2, solver=newton-cg;, score=0.093 total time=   2.0s\n",
      "[CV 2/4] END C=0.3, penalty=l2, solver=newton-cg;, score=0.111 total time=   2.1s\n",
      "[CV 3/4] END C=0.3, penalty=l2, solver=newton-cg;, score=0.100 total time=   1.5s\n",
      "[CV 4/4] END C=0.3, penalty=l2, solver=newton-cg;, score=0.086 total time=   2.1s\n",
      "[CV 1/4] END C=0.1, penalty=l2, solver=newton-cg;, score=0.107 total time=   1.4s\n",
      "[CV 2/4] END C=0.1, penalty=l2, solver=newton-cg;, score=0.114 total time=   1.4s\n",
      "[CV 3/4] END C=0.1, penalty=l2, solver=newton-cg;, score=0.098 total time=   2.1s\n",
      "[CV 4/4] END C=0.1, penalty=l2, solver=newton-cg;, score=0.091 total time=   1.0s\n",
      "[CV 1/4] END C=0.05, penalty=l2, solver=newton-cg;, score=0.114 total time=   0.9s\n",
      "[CV 2/4] END C=0.05, penalty=l2, solver=newton-cg;, score=0.125 total time=   1.0s\n",
      "[CV 3/4] END C=0.05, penalty=l2, solver=newton-cg;, score=0.105 total time=   1.0s\n",
      "[CV 4/4] END C=0.05, penalty=l2, solver=newton-cg;, score=0.098 total time=   1.2s\n",
      "best score:  0.11022727272727273\n",
      "best_params:  {'C': 0.05, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = dict(\n",
    "    solver=['newton-cg'],\n",
    "    penalty=['l2'],\n",
    "    C=[0.3, 0.1, 0.05]\n",
    ")\n",
    "\n",
    "\n",
    "grid_model = GridSearchCV(\n",
    "    estimator=LogisticRegression(),\n",
    "    param_grid=param_grid,\n",
    "    refit=True,\n",
    "    verbose=3,\n",
    "    cv=4,\n",
    ")\n",
    "\n",
    "grid_model.fit(valid_x_hard, valid_y_at_hard)\n",
    "\n",
    "print(\"best score: \", grid_model.best_score_)\n",
    "print(\"best_params: \", grid_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "413b5487-4bda-4341-8c20-c49e5ed47b14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 3 candidates, totalling 12 fits\n",
      "[CV 1/4] END C=0.07, penalty=l2, solver=newton-cg;, score=0.102 total time=   1.7s\n",
      "[CV 2/4] END C=0.07, penalty=l2, solver=newton-cg;, score=0.120 total time=   1.8s\n",
      "[CV 3/4] END C=0.07, penalty=l2, solver=newton-cg;, score=0.098 total time=   2.6s\n",
      "[CV 4/4] END C=0.07, penalty=l2, solver=newton-cg;, score=0.091 total time=   1.0s\n",
      "[CV 1/4] END C=0.05, penalty=l2, solver=newton-cg;, score=0.114 total time=   1.2s\n",
      "[CV 2/4] END C=0.05, penalty=l2, solver=newton-cg;, score=0.125 total time=   2.0s\n",
      "[CV 3/4] END C=0.05, penalty=l2, solver=newton-cg;, score=0.105 total time=   1.5s\n",
      "[CV 4/4] END C=0.05, penalty=l2, solver=newton-cg;, score=0.098 total time=   1.3s\n",
      "[CV 1/4] END C=0.03, penalty=l2, solver=newton-cg;, score=0.109 total time=   1.4s\n",
      "[CV 2/4] END C=0.03, penalty=l2, solver=newton-cg;, score=0.134 total time=   0.8s\n",
      "[CV 3/4] END C=0.03, penalty=l2, solver=newton-cg;, score=0.109 total time=   1.0s\n",
      "[CV 4/4] END C=0.03, penalty=l2, solver=newton-cg;, score=0.091 total time=   1.3s\n",
      "best score:  0.11079545454545453\n",
      "best_params:  {'C': 0.03, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = dict(\n",
    "    solver=['newton-cg'],\n",
    "    penalty=['l2'],\n",
    "    C=[0.07, 0.05, 0.03]\n",
    ")\n",
    "\n",
    "\n",
    "grid_model = GridSearchCV(\n",
    "    estimator=LogisticRegression(),\n",
    "    param_grid=param_grid,\n",
    "    refit=True,\n",
    "    verbose=3,\n",
    "    cv=4,\n",
    ")\n",
    "\n",
    "grid_model.fit(valid_x_hard, valid_y_at_hard)\n",
    "\n",
    "print(\"best score: \", grid_model.best_score_)\n",
    "print(\"best_params: \", grid_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5052f91b-ded7-4474-8ddf-0e419af0cae8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "[CV 1/4] END C=0.04, penalty=l2, solver=newton-cg;, score=0.109 total time=   1.6s\n",
      "[CV 2/4] END C=0.04, penalty=l2, solver=newton-cg;, score=0.127 total time=   1.7s\n",
      "[CV 3/4] END C=0.04, penalty=l2, solver=newton-cg;, score=0.107 total time=   1.0s\n",
      "[CV 4/4] END C=0.04, penalty=l2, solver=newton-cg;, score=0.095 total time=   0.7s\n",
      "[CV 1/4] END C=0.03, penalty=l2, solver=newton-cg;, score=0.109 total time=   1.2s\n",
      "[CV 2/4] END C=0.03, penalty=l2, solver=newton-cg;, score=0.134 total time=   1.1s\n",
      "[CV 3/4] END C=0.03, penalty=l2, solver=newton-cg;, score=0.109 total time=   1.1s\n",
      "[CV 4/4] END C=0.03, penalty=l2, solver=newton-cg;, score=0.091 total time=   1.1s\n",
      "[CV 1/4] END C=0.02, penalty=l2, solver=newton-cg;, score=0.107 total time=   0.7s\n",
      "[CV 2/4] END C=0.02, penalty=l2, solver=newton-cg;, score=0.118 total time=   1.6s\n",
      "[CV 3/4] END C=0.02, penalty=l2, solver=newton-cg;, score=0.111 total time=   1.1s\n",
      "[CV 4/4] END C=0.02, penalty=l2, solver=newton-cg;, score=0.091 total time=   1.0s\n",
      "[CV 1/4] END C=0.01, penalty=l2, solver=newton-cg;, score=0.107 total time=   1.0s\n",
      "[CV 2/4] END C=0.01, penalty=l2, solver=newton-cg;, score=0.105 total time=   0.9s\n",
      "[CV 3/4] END C=0.01, penalty=l2, solver=newton-cg;, score=0.118 total time=   0.6s\n",
      "[CV 4/4] END C=0.01, penalty=l2, solver=newton-cg;, score=0.091 total time=   0.3s\n",
      "best score:  0.11079545454545453\n",
      "best_params:  {'C': 0.03, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = dict(\n",
    "    solver=['newton-cg'],\n",
    "    penalty=['l2'],\n",
    "    C=[0.04, 0.03, 0.02, 0.01]\n",
    ")\n",
    "\n",
    "\n",
    "grid_model = GridSearchCV(\n",
    "    estimator=LogisticRegression(),\n",
    "    param_grid=param_grid,\n",
    "    refit=True,\n",
    "    verbose=3,\n",
    "    cv=4,\n",
    ")\n",
    "\n",
    "grid_model.fit(valid_x_hard, valid_y_at_hard)\n",
    "\n",
    "print(\"best score: \", grid_model.best_score_)\n",
    "print(\"best_params: \", grid_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34fb857c-e981-41b8-8247-cd38cba330eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_logistic_best(data_x, data_y):\n",
    "    clf = LogisticRegression(C=0.03, penalty=\"l2\", solver=\"newton-cg\")\n",
    "    clf.fit(data_x, data_y)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6265d14f-0499-41ef-ae6b-562377104e2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13055555555555556\n",
      "   prediction  label  check      prediction_name           label_name\n",
      "0          25     13  False           triangle_2  lord_of_the_dance_2\n",
      "1          20     13  False        thunderbolt_1  lord_of_the_dance_2\n",
      "3          32     13  False        warrior_III_1  lord_of_the_dance_2\n",
      "4          12     13  False  lord_of_the_dance_1  lord_of_the_dance_2\n",
      "5          35     13  False        warrior_III_4  lord_of_the_dance_2\n"
     ]
    }
   ],
   "source": [
    "save_path = \"/home/ubuntu/data/yg_ar/classic_models_hard_correctSIFT/logistic_best_at.pkl\"\n",
    "(\n",
    "    trained_svm_at, \n",
    "    predictions_svm_at, \n",
    "    accuracy_svm_at, \n",
    "    df_svm_at,\n",
    "    df_incorrect_svm_at, \n",
    "    df_correct_svm_at,\n",
    "    label_map_svm_at\n",
    ")= load_or_train(\n",
    "    train_x_hard, \n",
    "    train_y_at_hard, \n",
    "    test_x_hard, \n",
    "    test_y_at_hard, \n",
    "    train_logistic_best, \n",
    "    label_map_at_hard, \n",
    "    save_path\n",
    ")\n",
    "print(accuracy_svm_at)\n",
    "print(df_incorrect_svm_at.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b8a0197-5422-467a-9449-422e8dca096a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33425925925925926\n",
      "   prediction  label  check prediction_name         label_name\n",
      "0           6      3  False        triangle  lord_of_the_dance\n",
      "1           5      3  False     thunderbolt  lord_of_the_dance\n",
      "3           9      3  False     warrior_III  lord_of_the_dance\n",
      "4           6      3  False        triangle  lord_of_the_dance\n",
      "5           9      3  False     warrior_III  lord_of_the_dance\n"
     ]
    }
   ],
   "source": [
    "save_path = \"/home/ubuntu/data/yg_ar/classic_models_hard_correctSIFT/logistic_best_a.pkl\"\n",
    "(\n",
    "    trained_svm_a, \n",
    "    predictions_svm_a, \n",
    "    accuracy_svm_a, \n",
    "    df_svm_a, \n",
    "    df_incorrect_svm_a, \n",
    "    df_correct_svm_a,\n",
    "    label_map_svm_a\n",
    ")= load_or_train(\n",
    "    train_x_hard, \n",
    "    train_y_a_hard, \n",
    "    test_x_hard, \n",
    "    test_y_a_hard, \n",
    "    train_logistic_best, \n",
    "    label_map_a_hard, \n",
    "    save_path\n",
    ")\n",
    "print(accuracy_svm_a)\n",
    "print(df_incorrect_svm_a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a5bf7e-0b0e-4166-8cf0-4312487f97be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
