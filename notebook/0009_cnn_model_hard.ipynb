{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76c5d6e3-bedc-4500-906d-e5f936b1e513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# 1. weight on same class different type \n",
    "#     (predicting same class but different type should have a smaller error than different class)\n",
    "# 2. CNN\n",
    "# 3. Error analysis, by angle, by style, by randomness, weighted f1, confusion matrix\n",
    "# 4. error plots vs correctly predicted plots\n",
    "# 5. shap analysis \n",
    "# 6. transfer learning by vgg-16, trainable & not trainable\n",
    "# 7. use CV features as first layer\n",
    "# 8. PCA on raw pixels, check live session excercise 12\n",
    "# 9. maybe add KNN to classical models, use PCA & T-SNE hog features, similar to live session excercise 12\n",
    "# 10. visualize CNN filters\n",
    "# 11. identify hard samples in val set to do training analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf57e51-ef36-470a-8b56-c2c351f02342",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67e5d1e9-32f8-4108-99b3-3540ec8db73b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 16:41:00.568329: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-08 16:41:00.572037: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-04-08 16:41:00.572048: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Reshape, MaxPooling2D, Flatten, Dropout,BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.constraints import UnitNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78298696-f7ff-4661-b973-fc0eebcf1ebd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "import numpy as np\n",
    "\n",
    "from nebula.data.yg_ar.setup_data_image_hard import read_data\n",
    "from nebula.common import to_scale_one, write_pickle, read_pickle\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5817510d-9348-46fb-b50d-b3f7dcb8e01f",
   "metadata": {},
   "source": [
    "# Read data and apply label map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dae786af-2f1b-48b1-9cfe-e470c66021e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_label_map(labels):\n",
    "    label_set = set()\n",
    "    for lt in labels:\n",
    "        label_set.add(lt)\n",
    "\n",
    "    label_map = {}\n",
    "    count = 0\n",
    "    for l in label_set:\n",
    "        label_map[l] = count\n",
    "        count += 1\n",
    "        \n",
    "    return label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7ca643c-7212-4d33-852a-6486e62e072d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_path = \"/home/ubuntu/data/yg_ar/image_hard_df.pkl\"\n",
    "random_seed = 1\n",
    "df, train_df, test_df, valid_df = read_data(df_path, random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bf857a2-d5a4-4419-8319-17bc265b3a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_at_map = create_label_map(df[\"label_at\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9df58450-517a-4026-a42e-8326ab12ec1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = np.expand_dims(np.array([x for x in train_df.image]),axis=3)\n",
    "y_train = train_df.label_at.map(label_at_map).to_list()\n",
    "\n",
    "X_val = np.expand_dims(np.array([x for x in valid_df.image]),axis=3)\n",
    "y_val = valid_df.label_at.map(label_at_map).to_list()\n",
    "\n",
    "X_test = np.expand_dims(np.array([x for x in test_df.image]),axis=3)\n",
    "y_test = test_df.label_at.map(label_at_map).to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ab3618-e4f1-42b1-b468-38e6b9cf0329",
   "metadata": {},
   "source": [
    "# Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7dccc98-14b6-470d-9a88-f4dcec918eca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaled_X_train = X_train/255.0 \n",
    "scaled_X_val = X_val/255.0\n",
    "scaled_X_test = X_test/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1281c3e-7525-4cee-b19e-c700c319df5b",
   "metadata": {},
   "source": [
    "# Define CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3771efd-87d9-41b3-b79f-a61e0f6db772",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 16:41:05.210201: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ubuntu/.local/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2023-04-08 16:41:05.210231: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-04-08 16:41:05.210244: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-0-1-8): /proc/driver/nvidia/version does not exist\n",
      "2023-04-08 16:41:05.210450: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=3,padding='same',\\\n",
    "         activation='relu', kernel_initializer='he_normal',\\\n",
    "         # kernel_constraint=UnitNorm(), \\\n",
    "         input_shape = scaled_X_train[0].shape))\n",
    "model.add(Conv2D(32, kernel_size=3,padding='same',\\\n",
    "         activation='relu', kernel_initializer='he_normal',\\\n",
    "         # kernel_constraint=UnitNorm()\\\n",
    "                ))\n",
    "model.add(MaxPooling2D(pool_size = 2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=3,padding='same',\\\n",
    "         activation='relu', kernel_initializer='he_normal',\\\n",
    "         # kernel_constraint=UnitNorm()\\\n",
    "                ))\n",
    "model.add(Conv2D(64, kernel_size=3,padding='same',\\\n",
    "         activation='relu', kernel_initializer='he_normal',\\\n",
    "         # kernel_constraint=UnitNorm()\\\n",
    "                ))\n",
    "model.add(MaxPooling2D(pool_size = 2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=3,padding='same',\\\n",
    "         activation='relu', kernel_initializer='he_normal',\\\n",
    "         # kernel_constraint=UnitNorm()\\\n",
    "        ))\n",
    "model.add(Conv2D(128, kernel_size=3,padding='same',\\\n",
    "         activation='relu', kernel_initializer='he_normal',\\\n",
    "         # kernel_constraint=UnitNorm()\\\n",
    "                ))\n",
    "model.add(MaxPooling2D(pool_size = 2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=3,padding='same',\\\n",
    "         activation='relu', kernel_initializer='he_normal',\\\n",
    "         # kernel_constraint=UnitNorm()\\\n",
    "        ))\n",
    "model.add(Conv2D(256, kernel_size=3,padding='same',\\\n",
    "         activation='relu', kernel_initializer='he_normal',\\\n",
    "         # kernel_constraint=UnitNorm()\\\n",
    "                ))\n",
    "model.add(MaxPooling2D(pool_size = 2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=3,padding='same',\\\n",
    "         activation='relu', kernel_initializer='he_normal',\\\n",
    "         # kernel_constraint=UnitNorm()\\\n",
    "        ))\n",
    "model.add(Conv2D(512, kernel_size=3,padding='same',\\\n",
    "         activation='relu', kernel_initializer='he_normal',\\\n",
    "         # kernel_constraint=UnitNorm()\\\n",
    "        ))\n",
    "model.add(MaxPooling2D(pool_size = 2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "# model.add(Dense(256,activation='relu'))\n",
    "# model.add(Dropout(0.25))\n",
    "model.add(Dense(40,activation='softmax'))\n",
    "model.compile(Adam(learning_rate=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de1d004c-ab3c-4b80-953a-e87f742402e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Conv2D(32, kernel_size=3,padding='same', input_shape = scaled_X_train[0].shape))\n",
    "# model.add(MaxPooling2D(pool_size = 3))\n",
    "# model.add(Conv2D(64, kernel_size=3,padding='same'))\n",
    "# model.add(MaxPooling2D(pool_size = 3))\n",
    "# model.add(Conv2D(128, kernel_size=3,padding='same'))\n",
    "# model.add(MaxPooling2D(pool_size = 3))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(1024,activation='relu'))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Dense(40,activation='softmax'))\n",
    "# model.compile(Adam(learning_rate=0.0001,clipnorm=1.0),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc03b0cb-ec92-49ac-a163-96b6e16924c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 156, 156, 32)      320       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 156, 156, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 78, 78, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 78, 78, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 78, 78, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 78, 78, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 39, 39, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 39, 39, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 39, 39, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 39, 39, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 19, 19, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 19, 19, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 19, 19, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 19, 19, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 9, 9, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 9, 9, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 9, 9, 512)         1180160   \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 4, 4, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 4, 4, 512)        2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              8389632   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 40)                20520     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,650,568\n",
      "Trainable params: 13,648,584\n",
      "Non-trainable params: 1,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c3491b-7c56-42ef-9ab5-3a4a1f8cc8a8",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ab0f470-6d3d-4853-81d7-70c4f93d4279",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_accuracy',min_delta=0.001, patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "602dcc81-3bf3-430d-b8c8-6c70cbaede5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4020/4020 [==============================] - 447s 111ms/step - loss: 3.7231 - accuracy: 0.0483 - val_loss: 3.2723 - val_accuracy: 0.0750\n",
      "Epoch 2/100\n",
      "4020/4020 [==============================] - 440s 109ms/step - loss: 2.7987 - accuracy: 0.1716 - val_loss: 2.0215 - val_accuracy: 0.3295\n",
      "Epoch 3/100\n",
      "4020/4020 [==============================] - 448s 111ms/step - loss: 1.7281 - accuracy: 0.4096 - val_loss: 1.2260 - val_accuracy: 0.5545\n",
      "Epoch 4/100\n",
      "4020/4020 [==============================] - 436s 108ms/step - loss: 1.1300 - accuracy: 0.5838 - val_loss: 1.3859 - val_accuracy: 0.5352\n",
      "Epoch 5/100\n",
      "4020/4020 [==============================] - 435s 108ms/step - loss: 0.8125 - accuracy: 0.7012 - val_loss: 0.6952 - val_accuracy: 0.7494\n",
      "Epoch 6/100\n",
      "4020/4020 [==============================] - 436s 108ms/step - loss: 0.6255 - accuracy: 0.7692 - val_loss: 0.5895 - val_accuracy: 0.7824\n",
      "Epoch 7/100\n",
      "4020/4020 [==============================] - 447s 111ms/step - loss: 0.4983 - accuracy: 0.8150 - val_loss: 0.4505 - val_accuracy: 0.8358\n",
      "Epoch 8/100\n",
      "4020/4020 [==============================] - 479s 119ms/step - loss: 0.4163 - accuracy: 0.8479 - val_loss: 0.5269 - val_accuracy: 0.8097\n",
      "Epoch 9/100\n",
      "4020/4020 [==============================] - 479s 119ms/step - loss: 0.3552 - accuracy: 0.8712 - val_loss: 0.4032 - val_accuracy: 0.8591\n",
      "Epoch 10/100\n",
      "4020/4020 [==============================] - 479s 119ms/step - loss: 0.3062 - accuracy: 0.8886 - val_loss: 0.4131 - val_accuracy: 0.8625\n",
      "Epoch 11/100\n",
      "4020/4020 [==============================] - 479s 119ms/step - loss: 0.2719 - accuracy: 0.9053 - val_loss: 0.4895 - val_accuracy: 0.8460\n",
      "Epoch 12/100\n",
      "4020/4020 [==============================] - 479s 119ms/step - loss: 0.2407 - accuracy: 0.9162 - val_loss: 0.3226 - val_accuracy: 0.8926\n",
      "Epoch 13/100\n",
      "4020/4020 [==============================] - 479s 119ms/step - loss: 0.2186 - accuracy: 0.9238 - val_loss: 0.3184 - val_accuracy: 0.9011\n",
      "Epoch 14/100\n",
      "4020/4020 [==============================] - 479s 119ms/step - loss: 0.2104 - accuracy: 0.9297 - val_loss: 0.2593 - val_accuracy: 0.9114\n",
      "Epoch 15/100\n",
      "4020/4020 [==============================] - 479s 119ms/step - loss: 0.1843 - accuracy: 0.9374 - val_loss: 0.2684 - val_accuracy: 0.9153\n",
      "Epoch 16/100\n",
      "4020/4020 [==============================] - 479s 119ms/step - loss: 0.1604 - accuracy: 0.9451 - val_loss: 0.4455 - val_accuracy: 0.8699\n",
      "Epoch 17/100\n",
      "4020/4020 [==============================] - 479s 119ms/step - loss: 0.1652 - accuracy: 0.9450 - val_loss: 0.3411 - val_accuracy: 0.9023\n",
      "Epoch 18/100\n",
      "4020/4020 [==============================] - 479s 119ms/step - loss: 0.1508 - accuracy: 0.9509 - val_loss: 0.2891 - val_accuracy: 0.9205\n",
      "Epoch 19/100\n",
      "4020/4020 [==============================] - 479s 119ms/step - loss: 0.1379 - accuracy: 0.9561 - val_loss: 0.3540 - val_accuracy: 0.9000\n",
      "Epoch 20/100\n",
      "4020/4020 [==============================] - 477s 119ms/step - loss: 0.1343 - accuracy: 0.9562 - val_loss: 0.3026 - val_accuracy: 0.9097\n",
      "Epoch 21/100\n",
      "4020/4020 [==============================] - 480s 119ms/step - loss: 0.1197 - accuracy: 0.9601 - val_loss: 0.6407 - val_accuracy: 0.8705\n",
      "Epoch 22/100\n",
      "4020/4020 [==============================] - 479s 119ms/step - loss: 0.1154 - accuracy: 0.9634 - val_loss: 0.2543 - val_accuracy: 0.9335\n",
      "Epoch 23/100\n",
      "4020/4020 [==============================] - 479s 119ms/step - loss: 0.1263 - accuracy: 0.9603 - val_loss: 0.3043 - val_accuracy: 0.9159\n",
      "Epoch 24/100\n",
      "4020/4020 [==============================] - 479s 119ms/step - loss: 0.1080 - accuracy: 0.9641 - val_loss: 0.5337 - val_accuracy: 0.8972\n",
      "Epoch 25/100\n",
      "4020/4020 [==============================] - 479s 119ms/step - loss: 0.0967 - accuracy: 0.9699 - val_loss: 0.3078 - val_accuracy: 0.9182\n",
      "Epoch 26/100\n",
      "4020/4020 [==============================] - 479s 119ms/step - loss: 0.0894 - accuracy: 0.9715 - val_loss: 0.3662 - val_accuracy: 0.9125\n",
      "Epoch 27/100\n",
      "4020/4020 [==============================] - 480s 119ms/step - loss: 0.1003 - accuracy: 0.9675 - val_loss: 0.3638 - val_accuracy: 0.9239\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe4a8e9bb80>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_X_train, to_categorical(y_train),\\\n",
    "          batch_size=4,\\\n",
    "          epochs=100,\\\n",
    "          validation_data = (scaled_X_val,to_categorical(y_val)),\\\n",
    "          callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b7007d-24c3-419a-b376-fe2d3c454a7c",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db5579f4-3a00-4445-8a0e-2e2e5e8fda4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 17s 244ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96        54\n",
      "           1       0.94      0.89      0.91        54\n",
      "           2       0.96      0.83      0.89        54\n",
      "           3       1.00      0.91      0.95        54\n",
      "           4       0.85      0.94      0.89        54\n",
      "           5       0.94      0.87      0.90        54\n",
      "           6       0.84      0.78      0.81        54\n",
      "           7       1.00      0.96      0.98        54\n",
      "           8       0.87      0.98      0.92        54\n",
      "           9       0.94      0.81      0.87        54\n",
      "          10       0.81      0.72      0.76        54\n",
      "          11       0.83      0.89      0.86        54\n",
      "          12       0.96      0.94      0.95        54\n",
      "          13       0.96      0.96      0.96        54\n",
      "          14       0.93      0.98      0.95        54\n",
      "          15       1.00      0.96      0.98        54\n",
      "          16       0.89      0.89      0.89        54\n",
      "          17       0.90      0.96      0.93        54\n",
      "          18       0.93      0.98      0.95        54\n",
      "          19       0.98      0.98      0.98        54\n",
      "          20       0.90      0.96      0.93        54\n",
      "          21       0.91      0.94      0.93        54\n",
      "          22       0.93      0.94      0.94        54\n",
      "          23       0.95      0.96      0.95        54\n",
      "          24       0.96      0.93      0.94        54\n",
      "          25       0.96      0.80      0.87        54\n",
      "          26       0.94      0.87      0.90        54\n",
      "          27       0.95      0.98      0.96        54\n",
      "          28       0.70      0.93      0.80        54\n",
      "          29       0.84      0.87      0.85        54\n",
      "          30       0.91      0.94      0.93        54\n",
      "          31       0.96      0.96      0.96        54\n",
      "          32       0.84      0.94      0.89        54\n",
      "          33       0.96      0.89      0.92        54\n",
      "          34       0.89      0.89      0.89        54\n",
      "          35       0.98      0.87      0.92        54\n",
      "          36       0.94      0.91      0.92        54\n",
      "          37       0.90      1.00      0.95        54\n",
      "          38       0.96      0.98      0.97        54\n",
      "          39       0.96      0.96      0.96        54\n",
      "\n",
      "    accuracy                           0.92      2160\n",
      "   macro avg       0.92      0.92      0.92      2160\n",
      "weighted avg       0.92      0.92      0.92      2160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(model.predict(scaled_X_test),axis=1)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c91358-2e1d-40b6-9003-06238182352b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
