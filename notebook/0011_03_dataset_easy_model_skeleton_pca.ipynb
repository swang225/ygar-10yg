{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b21268a-5c59-4575-a591-afcd0fa11b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aphri\\miniconda3\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: [WinError 127] The specified procedure could not be found\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nebula.data.yg_ar.setup_data_image_hard import read_data\n",
    "from nebula.common import to_scale_one, write_pickle, read_pickle\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d6aa2df-d80c-403c-b0a9-33557679ae7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label_map(labels):\n",
    "    label_set = set()\n",
    "    for lt in labels:\n",
    "        label_set.add(lt)\n",
    "        \n",
    "    label_set = list(label_set)\n",
    "    label_set.sort()\n",
    "\n",
    "    label_map = {}\n",
    "    count = 0\n",
    "    for l in label_set:\n",
    "        label_map[l] = count\n",
    "        count += 1\n",
    "        \n",
    "    return label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88a61a52-7118-41fe-a695-77ff63c615a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = \"C:/Users/aphri/Documents/t0002/pycharm/data/yg_ar/image_easy2_ds_skeleton_pca.pkl\"\n",
    "df, train_df, test_df, valid_df = read_pickle(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99b999c1-de4d-4244-9acc-7b791049f8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map_a = create_label_map(df[\"label_a\"])\n",
    "label_map_at = create_label_map(df[\"label_at\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bce63941-c9fc-4c11-9fbf-4947ee998238",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_df[\"image\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fd5319f-95ee-4a1a-a056-c755af2930bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_a = train_df[\"label_a\"].map(label_map_a).to_list()\n",
    "train_y_at = train_df[\"label_at\"].map(label_map_at).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f21f1acf-b2c2-4f1d-87f8-093f2da21874",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = test_df[\"image\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fefefe69-772d-4d2a-ae8f-88c4f158a291",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_a = test_df[\"label_a\"].map(label_map_a).to_list()\n",
    "test_y_at = test_df[\"label_at\"].map(label_map_at).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b2c2f26-4604-47b8-9ca8-403a0d7e69d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm(data_x, data_y):\n",
    "    clf = svm.SVC(max_iter=50)\n",
    "    clf.fit(data_x, data_y)\n",
    "    return clf\n",
    "\n",
    "\n",
    "def train_logistic(data_x, data_y):\n",
    "    clf = LogisticRegression(random_state=0)\n",
    "    clf.fit(data_x, data_y)\n",
    "    return clf\n",
    "\n",
    "\n",
    "def train_gbt(data_x, data_y):\n",
    "    clf = GradientBoostingClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=3,\n",
    "        random_state=0,\n",
    "        verbose=1,\n",
    "        n_iter_no_change=2,\n",
    "    )\n",
    "    clf.fit(data_x, data_y)\n",
    "    return clf\n",
    "\n",
    "\n",
    "def evaluate(model, test_x, test_y):\n",
    "    res = model.predict(test_x)\n",
    "    correct = res == test_y\n",
    "    accuracy = correct.sum() / len(res)\n",
    "    return res, accuracy\n",
    "\n",
    "\n",
    "def create_dirs_to_file(path):\n",
    "    dirs = \"/\".join(osp.join(path).split(\"/\")[:-1])\n",
    "    if not osp.exists(dirs):\n",
    "        os.makedirs(dirs)\n",
    "\n",
    "\n",
    "def load_or_train(train_x, train_y, test_x, test_y, train_func, label_map, path):\n",
    "    \n",
    "    if osp.exists(path):\n",
    "        return read_pickle(path)\n",
    "    \n",
    "    create_dirs_to_file(path)\n",
    "    \n",
    "    trained_model = train_func(train_x, train_y)\n",
    "    predictions, accuracy = evaluate(trained_model, test_x, test_y)\n",
    "    \n",
    "    df, df_incorrect, df_correct = format_results(predictions, test_y, label_map)\n",
    "    \n",
    "    write_pickle(path, (trained_model, predictions, accuracy, df, df_incorrect, df_correct, label_map)) \n",
    "    \n",
    "    return trained_model, predictions, accuracy, df, df_incorrect, df_correct, label_map\n",
    "\n",
    "\n",
    "def format_results(predictions, labels, label_map):\n",
    "    df = pd.DataFrame(\n",
    "        data={\n",
    "            \"prediction\": predictions,\n",
    "            \"label\": labels\n",
    "        }\n",
    "    )\n",
    "    df[\"check\"] = df[\"prediction\"] == df[\"label\"]\n",
    "\n",
    "    label_map_reverse = {v:k for k, v in label_map.items()}\n",
    "\n",
    "    df[\"prediction_name\"] = df.prediction.map(label_map_reverse)\n",
    "    df[\"label_name\"] = df.label.map(label_map_reverse)\n",
    "\n",
    "    df_incorrect = df[~df.check]\n",
    "    df_correct = df[df.check]\n",
    "\n",
    "    return df, df_incorrect, df_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07de2998-8e41-4921-a595-d1096dfa7952",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aphri\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4759259259259259\n",
      "   prediction  label  check prediction_name label_name\n",
      "0           7      2  False      upward_dog     childs\n",
      "1           1      2  False           chair     childs\n",
      "3           9      2  False     warrior_III     childs\n",
      "5           0      2  False           camel     childs\n",
      "6           4      2  False           lotus     childs\n"
     ]
    }
   ],
   "source": [
    "save_path = \"C:/Users/aphri/Documents/t0002/pycharm/data/yg_ar/classic_models_easy2_skeleton_new_pca/svm_a.pkl\"\n",
    "(\n",
    "    trained_svm_a, \n",
    "    predictions_svm_a, \n",
    "    accuracy_svm_a, \n",
    "    df_svm_a, \n",
    "    df_incorrect_svm_a, \n",
    "    df_correct_svm_a,\n",
    "    label_map_svm_a\n",
    ")= load_or_train(\n",
    "    train_x, \n",
    "    train_y_a, \n",
    "    test_x, \n",
    "    test_y_a, \n",
    "    train_svm, \n",
    "    label_map_a, \n",
    "    save_path\n",
    ")\n",
    "print(accuracy_svm_a)\n",
    "print(df_incorrect_svm_a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66359b0a-dfe3-40b8-b97c-d1af8342f837",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aphri\\miniconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3347222222222222\n",
      "   prediction  label  check prediction_name label_name\n",
      "0          10      8  False        childs_3   childs_1\n",
      "1           7      8  False         chair_4   childs_1\n",
      "2          10      8  False        childs_3   childs_1\n",
      "3          30      8  False    upward_dog_3   childs_1\n",
      "4           9      8  False        childs_2   childs_1\n"
     ]
    }
   ],
   "source": [
    "save_path = \"C:/Users/aphri/Documents/t0002/pycharm/data/yg_ar/classic_models_easy2_skeleton_new_pca/svm_at.pkl\"\n",
    "(\n",
    "    trained_svm_at, \n",
    "    predictions_svm_at, \n",
    "    accuracy_svm_at, \n",
    "    df_svm_at,\n",
    "    df_incorrect_svm_at, \n",
    "    df_correct_svm_at,\n",
    "    label_map_svm_at\n",
    ")= load_or_train(\n",
    "    train_x, \n",
    "    train_y_at, \n",
    "    test_x, \n",
    "    test_y_at, \n",
    "    train_svm, \n",
    "    label_map_at, \n",
    "    save_path\n",
    ")\n",
    "print(accuracy_svm_at)\n",
    "print(df_incorrect_svm_at.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98a75f18-62af-48c3-aed8-c9dc7196d1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47175925925925927\n",
      "    prediction  label  check prediction_name label_name\n",
      "0            4      2  False           lotus     childs\n",
      "5            4      2  False           lotus     childs\n",
      "7            4      2  False           lotus     childs\n",
      "9            5      2  False     thunderbolt     childs\n",
      "10           4      2  False           lotus     childs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aphri\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "save_path = \"C:/Users/aphri/Documents/t0002/pycharm/data/yg_ar/classic_models_easy2_skeleton_new_pca/logistic_a.pkl\"\n",
    "(\n",
    "    trained_logistic_a, \n",
    "    predictions_logistic_a, \n",
    "    accuracy_logistic_a, \n",
    "    df_logistic_a,\n",
    "    df_incorrect_logistic_a, \n",
    "    df_correct_logistic_a,\n",
    "    label_map_logistic_a\n",
    ")= load_or_train(\n",
    "    train_x, \n",
    "    train_y_a, \n",
    "    test_x, \n",
    "    test_y_a, \n",
    "    train_logistic, \n",
    "    label_map_a, \n",
    "    save_path\n",
    ")\n",
    "print(accuracy_logistic_a)\n",
    "print(df_incorrect_logistic_a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c02bb52-29e4-4650-9336-4a9a406395df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15648148148148147\n",
      "   prediction  label  check prediction_name label_name\n",
      "0          18      8  False         lotus_3   childs_1\n",
      "3          21      8  False   thunderbolt_2   childs_1\n",
      "4           9      8  False        childs_2   childs_1\n",
      "5          19      8  False         lotus_4   childs_1\n",
      "6           9      8  False        childs_2   childs_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aphri\\miniconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "save_path = \"C:/Users/aphri/Documents/t0002/pycharm/data/yg_ar/classic_models_easy2_skeleton_new_pca/logistic_at.pkl\"\n",
    "(\n",
    "    trained_logistic_at, \n",
    "    predictions_logistic_at, \n",
    "    accuracy_logistic_at, \n",
    "    df_logistic_at,\n",
    "    df_incorrect_logistic_at, \n",
    "    df_correct_logistic_at,\n",
    "    label_map_logistic_at\n",
    ")= load_or_train(\n",
    "    train_x, \n",
    "    train_y_at, \n",
    "    test_x, \n",
    "    test_y_at, \n",
    "    train_logistic, \n",
    "    label_map_at, \n",
    "    save_path\n",
    ")\n",
    "print(accuracy_logistic_at)\n",
    "print(df_incorrect_logistic_at.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a42d41d-2ee1-4d85-90eb-1acc3756f7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7217592592592592\n",
      "    prediction  label  check prediction_name  label_name\n",
      "20           0      7  False           camel  upward_dog\n",
      "28           6      7  False        triangle  upward_dog\n",
      "34           2      7  False          childs  upward_dog\n",
      "53           0      7  False           camel  upward_dog\n",
      "58           8      0  False      warrior_II       camel\n"
     ]
    }
   ],
   "source": [
    "save_path = \"C:/Users/aphri/Documents/t0002/pycharm/data/yg_ar/classic_models_easy2_skeleton_new_pca/gbt01_a.pkl\"\n",
    "(\n",
    "    trained_gbt_a, \n",
    "    predictions_gbt_a, \n",
    "    accuracy_gbt_a, \n",
    "    df_gbt_a, \n",
    "    df_incorrect_gbt_a, \n",
    "    df_correct_gbt_a,\n",
    "    label_map_gbt_a\n",
    ")= load_or_train(\n",
    "    train_x, \n",
    "    train_y_a, \n",
    "    test_x, \n",
    "    test_y_a, \n",
    "    train_gbt, \n",
    "    label_map_a, \n",
    "    save_path\n",
    ")\n",
    "print(accuracy_gbt_a)\n",
    "print(df_incorrect_gbt_a.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f38dd9-b491-48bb-adff-bd7c0b59b7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           3.5059          353.03m\n"
     ]
    }
   ],
   "source": [
    "save_path = \"C:/Users/aphri/Documents/t0002/pycharm/data/yg_ar/classic_models_easy2_skeleton_new_pca/gbt01_at.pkl\"\n",
    "(\n",
    "    trained_gbt_at, \n",
    "    predictions_gbt_at, \n",
    "    accuracy_gbt_at, \n",
    "    df_gbt_at, \n",
    "    df_incorrect_gbt_at, \n",
    "    df_correct_gbt_at,\n",
    "    label_map_gbt_at\n",
    ")= load_or_train(\n",
    "    train_x, \n",
    "    train_y_at, \n",
    "    test_x, \n",
    "    test_y_at, \n",
    "    train_gbt, \n",
    "    label_map_at, \n",
    "    save_path\n",
    ")\n",
    "print(accuracy_gbt_at)\n",
    "print(df_incorrect_gbt_at.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85ed307-80fc-4e1e-a96f-5209982e8d03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
