{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41689ce4-5d32-4ee6-9438-e02fea09d601",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aphri\\miniconda3\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: [WinError 127] The specified procedure could not be found\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import os.path as osp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from skimage.morphology import skeletonize\n",
    "from skimage.util import invert\n",
    "from nebula.common import to_scale_one, write_pickle, read_pickle, to_pca\n",
    "from nebula.data.yg_ar.setup_data_image_hard import split_ar_anim_df\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f7f0b8f-f57d-4fa7-a4cc-339913d6ceb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(frame):\n",
    "\n",
    "    # display results\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(4, 4))\n",
    "\n",
    "    ax.imshow(frame, cmap=plt.cm.gray)\n",
    "    ax.axis('off')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def display2(f1, f2):\n",
    "    \n",
    "    # display results\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(8, 4),\n",
    "                             sharex=True, sharey=True)\n",
    "\n",
    "    ax = axes.ravel()\n",
    "\n",
    "    ax[0].imshow(f1, cmap=plt.cm.gray)\n",
    "    ax[0].axis('off')\n",
    "    ax[0].set_title('image 1', fontsize=20)\n",
    "\n",
    "    ax[1].imshow(f2, cmap=plt.cm.gray)\n",
    "    ax[1].axis('off')\n",
    "    ax[1].set_title('image 2', fontsize=20)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def get_loc_frame_from_data(data, loc=0.5):\n",
    "    count = data.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    f_loc = int((count-1) * loc)\n",
    "    \n",
    "    data.set(cv2.CAP_PROP_POS_FRAMES, f_loc)\n",
    "    ret, frame = data.read()\n",
    "    \n",
    "    return frame\n",
    "    \n",
    "    \n",
    "def get_loc_frame(path, loc=0.5):\n",
    "    data = cv2.VideoCapture(path)\n",
    "    return get_loc_frame_from_data(data, loc=loc)\n",
    "\n",
    "\n",
    "def get_n_frames(path, n=8):\n",
    "    data = cv2.VideoCapture(path)\n",
    "    res = [get_loc_frame_from_data(data, loc=i/n) for i in range(n)]\n",
    "    \n",
    "    return res\n",
    "\n",
    "\n",
    "def get_locs_frames(path, locs=[0.15, 0.5, 0.85]):\n",
    "    data = cv2.VideoCapture(path)\n",
    "    res = [get_loc_frame_from_data(data, loc=loc) for loc in locs]\n",
    "    return res\n",
    "    \n",
    "\n",
    "def to_gray_one(frame):\n",
    "    return cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "def to_gray(frames):\n",
    "    res = [to_gray_one(f) for f in frames]\n",
    "    return res\n",
    "\n",
    "\n",
    "def crop_one(frame, top, bottom, left, right):\n",
    "    return frame[top:-bottom, left:-right]\n",
    "\n",
    "\n",
    "def crop(frames, top, bottom, left, right):\n",
    "    res = [crop_one(f, top, bottom, left, right) for f in frames]\n",
    "    return res\n",
    "\n",
    "\n",
    "def save_frame(path, frame):\n",
    "    cv2.imwrite(path, frame)\n",
    "    \n",
    "\n",
    "def read_gray_frame(path):\n",
    "    return cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    \n",
    "def to_jpg_name(file):\n",
    "    return file.split(\".\")[0] + \".jpg\"\n",
    "\n",
    "\n",
    "def to_pickle_name(file):\n",
    "    return file.split(\".\")[0] + \".pkl\"\n",
    "\n",
    "\n",
    "def get_files(dir, format=None):\n",
    "    res = []\n",
    "    for filename in os.listdir(dir):\n",
    "        if format is None or filename.split(\".\")[-1] == format:\n",
    "            res.append(filename)\n",
    "    return res\n",
    "\n",
    "\n",
    "def filename_to_labels(filename):\n",
    "    \n",
    "    filename = filename.split(\".\")[0]\n",
    "    words = filename.split(\"_\")\n",
    "    \n",
    "    orientation = words[-1]\n",
    "    xangle = words[-2]\n",
    "    yangle = words[-3]\n",
    "    pants = words[-4]\n",
    "    cloth = words[-6]\n",
    "    hair = words[-8]\n",
    "    action_type = words[-10]\n",
    "    label = \"_\".join(words[:-10])\n",
    "    \n",
    "    return (\n",
    "        orientation, \n",
    "        xangle, \n",
    "        yangle, \n",
    "        pants, \n",
    "        cloth, \n",
    "        hair, \n",
    "        action_type, \n",
    "        label\n",
    "    )\n",
    "\n",
    "\n",
    "def filename_to_labels_hard(filename):\n",
    "    \n",
    "    filename = filename.split(\".\")[0]\n",
    "    words = filename.split(\"_\")\n",
    "    \n",
    "    action = \"_\".join(words[:-12])\n",
    "    action_type = words[-12]\n",
    "    \n",
    "    label_a = action\n",
    "    label_at = \"_\".join([action, action_type])\n",
    "    \n",
    "    return (\n",
    "        label_a,\n",
    "        label_at,\n",
    "        filename\n",
    "    )\n",
    "\n",
    "\n",
    "def read_pickle(dir):\n",
    "    with open(dir, 'rb') as handle:\n",
    "        b = pickle.load(handle)\n",
    "    return b\n",
    "\n",
    "\n",
    "def write_pickle(dir, data):\n",
    "    with open(dir, 'wb') as handle:\n",
    "        pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6308f76-c151-41c2-88bc-b7ba06a40882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_middle_frame(\n",
    "    base_dir,\n",
    "    save_dir,\n",
    "    overwrite=False,\n",
    "    crop=dict(top=70, bottom=30, left=50, right=50)\n",
    "):\n",
    "    if not osp.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    files = get_files(base_dir)\n",
    "    count = len(files)\n",
    "    prev_progress = 0\n",
    "    for i, file in enumerate(files):\n",
    "        save_file = osp.join(save_dir, to_jpg_name(file))\n",
    "        if osp.exists(save_file) and not overwrite:\n",
    "            continue\n",
    "        \n",
    "        path = osp.join(base_dir, file)\n",
    "        frame = to_gray_one(crop_one(get_loc_frame(path), **crop))\n",
    "        \n",
    "        save_frame(save_file, frame)\n",
    "        \n",
    "        cur_progress = int((i+1)*100/count)\n",
    "        if cur_progress >= prev_progress + 2:\n",
    "            print(f\"progress: {cur_progress}%\")\n",
    "            prev_progress = cur_progress\n",
    "            \n",
    "\n",
    "def df_middle_frame(\n",
    "    image_dir,\n",
    "    save_path,\n",
    "):\n",
    "    files = get_files(image_dir)\n",
    "    count = len(files)\n",
    "    print(count)\n",
    "    prev_progress = 0\n",
    "    res = []\n",
    "    for i, f in enumerate(files):\n",
    "        frame = read_gray_frame(osp.join(image_dir, f))\n",
    "        (\n",
    "            label_a,\n",
    "            label_ac,\n",
    "            fname\n",
    "        ) = filename_to_labels_hard(f)\n",
    "        \n",
    "        res.append(\n",
    "            (\n",
    "                frame, \n",
    "                label_a,\n",
    "                label_ac,\n",
    "                fname\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        cur_progress = int((i+1)*100/count)\n",
    "        if cur_progress >= prev_progress + 2:\n",
    "            print(f\"progress: {cur_progress}%\")\n",
    "            prev_progress = cur_progress\n",
    "\n",
    "    df = pd.DataFrame(data=dict(zip(\n",
    "        [\n",
    "            \"image\", \n",
    "            \"label_a\",\n",
    "            \"label_at\",\n",
    "            \"file_name\"\n",
    "        ], \n",
    "        np.transpose(res)\n",
    "    )))\n",
    "    \n",
    "    df.to_pickle(save_path)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "438c6e2a-bbf5-4f12-aff4-fa0aaecb046f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_locs_frames(\n",
    "    base_dir,\n",
    "    save_dir,\n",
    "    overwrite=False,\n",
    "    crop=dict(top=70, bottom=30, left=50, right=50),\n",
    "    locs=[0.15, 0.5, 0.85]\n",
    "):\n",
    "    if not osp.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    files = get_files(base_dir)\n",
    "    count = len(files)\n",
    "    prev_progress = 0\n",
    "    for i, file in enumerate(files):\n",
    "        save_file = osp.join(save_dir, to_pickle_name(file))\n",
    "        if osp.exists(save_file) and not overwrite:\n",
    "            continue\n",
    "        \n",
    "        path = osp.join(base_dir, file)\n",
    "        frames = get_locs_frames(path, locs=locs)\n",
    "        frames = [to_gray_one(crop_one(f, **crop)) for f in frames]\n",
    "        \n",
    "        write_pickle(save_file, frames)\n",
    "        \n",
    "        cur_progress = int((i+1)*100/count)\n",
    "        if cur_progress >= prev_progress + 2:\n",
    "            print(f\"progress: {cur_progress}%\")\n",
    "            prev_progress = cur_progress\n",
    "            \n",
    "\n",
    "def df_locs_frames(\n",
    "    pickle_dir,\n",
    "    save_path,\n",
    "):\n",
    "    files = get_files(pickle_dir)\n",
    "    count = len(files)\n",
    "    print(count)\n",
    "    prev_progress = 0\n",
    "    res = []\n",
    "    for i, f in enumerate(files):\n",
    "        frames = read_pickle(osp.join(pickle_dir, f))\n",
    "        (\n",
    "            label_a,\n",
    "            label_ac,\n",
    "            fname\n",
    "        ) = filename_to_labels_hard(f)\n",
    "        \n",
    "        res.append(\n",
    "            (\n",
    "                frames, \n",
    "                label_a,\n",
    "                label_ac,\n",
    "                fname\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        cur_progress = int((i+1)*100/count)\n",
    "        if cur_progress >= prev_progress + 2:\n",
    "            print(f\"progress: {cur_progress}%\")\n",
    "            prev_progress = cur_progress\n",
    "\n",
    "    df = pd.DataFrame(data=dict(zip(\n",
    "        [\n",
    "            \"images\", \n",
    "            \"label_a\",\n",
    "            \"label_at\",\n",
    "            \"file_name\"\n",
    "        ], \n",
    "        np.transpose(res)\n",
    "    )))\n",
    "    \n",
    "    df.to_pickle(save_path)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95381148-6e11-4da7-96e4-6c0478790aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "from scipy import ndimage\n",
    "import random\n",
    "\n",
    "\n",
    "def zoom(frame, x, y, z=100):\n",
    "    img = Image.fromarray(frame)\n",
    "    w, h = img.size\n",
    "    z2 = z * 2/100.0\n",
    "    img = img.crop((x - w / z2, y - h / z2, \n",
    "                    x + w / z2, y + h / z2))\n",
    "    img = img.resize((w, h), Image.LANCZOS)\n",
    "    return np.asarray(img)\n",
    "\n",
    "\n",
    "def rotate(frame, degree):\n",
    "    return ndimage.rotate(frame, degree, reshape=False)\n",
    "\n",
    "\n",
    "def random_zoom(frame, min_loc=-10, max_loc=10, min_z=100, max_z=130):\n",
    "    \n",
    "    h, w = frame.shape\n",
    "    \n",
    "    x_offset = random.randint(min_loc, max_loc)\n",
    "    y_offset = random.randint(min_loc, max_loc)\n",
    "    z = random.randint(min_z, max_z)\n",
    "    \n",
    "    return zoom(frame, int(w/2)+x_offset, int(h/2)+y_offset, z)\n",
    "\n",
    "\n",
    "def random_rotate(frame, min_d=-10, max_d=10):\n",
    "    \n",
    "    deg = random.randint(min_d, max_d)\n",
    "    return rotate(frame, deg)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94e0b044-b609-4a7f-b7ca-362b02ecc2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'C:/Users/aphri/Documents/t0002/pycharm/data/yg_ar/videos_medium'\n",
    "save_dir = 'C:/Users/aphri/Documents/t0002/pycharm/data/yg_ar/middle_image_medium'\n",
    "image_pickle_path = 'C:/Users/aphri/Documents/t0002/pycharm/data/yg_ar/image_medium_df.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0482a66-e1f3-4927-9717-8063d8b95083",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = read_pickle(image_pickle_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "703b43ee-fd9f-4518-a980-4eceb2362e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def point2_scale(df):\n",
    "    df = df.copy()\n",
    "    df[\"image\"] = df[\"image\"].apply(lambda x: to_scale_one(x, scale=0.2).flatten())\n",
    "    df[\"image\"] = df[\"image\"] / 225\n",
    "    random_seed = 1\n",
    "    train_df, test_df, valid_df = split_ar_anim_df(df, random_seed)\n",
    "    train_df = train_df.sample(frac=1, random_state=random_seed)  # randomize train_df\n",
    "    return df, train_df, test_df, valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b07d9c1-5eda-4be6-a2bc-284086afbbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, train_df, test_df, valid_df = point2_scale(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0468ea3-c9aa-4c8a-b157-d8c2f30e8221",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'C:/Users/aphri/Documents/t0002/pycharm/data/yg_ar/image_medium_ds_point2_scale.pkl'\n",
    "write_pickle(data_path, (df, train_df, test_df, valid_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7bfd4af-c7f3-498b-8bc1-5048dcef59ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"image\"] = df2[\"image\"].apply(lambda x: to_scale_one(x, scale=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48689df0-a0e0-4b08-a500-c8ea4feaa091",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, eigen_imgs, pca = to_pca(df2, n_components=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ae80c13-15f2-4e7c-b930-b7e47476c08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df2.copy()\n",
    "df[\"image\"] = pd.Series(data=[w for w in weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c61eeb94-eb8a-448e-8d21-64520ba05cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 1\n",
    "train_df, test_df, valid_df = split_ar_anim_df(df, random_seed)\n",
    "train_df = train_df.sample(frac=1, random_state=random_seed)  # randomize train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "252bd688-b23d-47b1-8d80-f13635fb0004",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'C:/Users/aphri/Documents/t0002/pycharm/data/yg_ar/image_medium_ds_pca.pkl'\n",
    "write_pickle(data_path, (df, train_df, test_df, valid_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffdb348-2341-4f6f-a561-30e6f87e1e0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
